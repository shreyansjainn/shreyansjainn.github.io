<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Notes - Mechanistic? | Shreyans Jain </title> <meta name="author" content="Shreyans Jain"> <meta name="description" content="Paper Notes for the `Mechanistic?` Paper"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shreyansjainn.github.io/blog/2026/mechanistic/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}};</script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shreyans Jain </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/favblog/">repeat reads </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Notes - Mechanistic?</h1> <p class="post-meta"> Created in January 30, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/paper-notes"> <i class="fa-solid fa-hashtag fa-sm"></i> paper-notes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Recently I’ve been really questionning the field of Interpretability, in terms of its potential future, potential for success and the differences it can make, so I’ve been thinking about it from a more fundamental level, mainly to improve my understanding from a meta pov as well as technical, so I thought I should do an exercise where I try to jot down my notes of a paper in my own language and share it across. These are my interpretations and notes on the paper, so I apologise in advance for any misinterpretation or mistakes.</p> <p>First Paper I’ve chosen is a paper named <a href="https://arxiv.org/abs/2410.09087" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">Mechanistic?</code></a>. It takes about the origins of Mechanistic Interpretability as a term, a field of research and a community. So here we go…</p> <p><br></p> <h1 id="what-do-we-really-mean-by-mechanistic-interpretability">What Do We Really Mean by Mechanistic Interpretability?</h1> <p>Mechanistic Interpretability (MI) has become one of the most widely used—and most ambiguously defined—terms in modern AI interpretability research. Depending on who you ask, it can mean anything from causal reverse-engineering of neural networks to simply visualizing activations. This ambiguity is not accidental; it is the product of overlapping definitions, disciplinary histories, and community-driven norms. In this post, I unpack where this confusion comes from, how MI differs (and overlaps) with NLP Interpretability (NLPI), and why these tensions matter for the future of the field.</p> <h2 id="four-and-a-half-definitions-of-mechanistic-interpretability">Four (and a Half) Definitions of Mechanistic Interpretability</h2> <p>The term mechanistic interpretability is currently overloaded. At least four distinct definitions circulate in the literature and community discourse:</p> <ol> <li> <strong>Narrow technical definition:</strong> A research program focused on understanding neural networks through their causal mechanisms.</li> <li> <strong>Broad technical definition</strong>: Any work that studies model internals—weights, activations, attention patterns, or intermediate representations.</li> <li> <strong>Narrow cultural definition</strong>: Research originating from the MI community, historically associated with forums like Distill, LessWrong, or the AI Alignment Forum.</li> <li> <strong>Broad cultural definition:</strong> Interpretability research in AI at large, especially in language models.</li> <li> <strong>Author-based definition (implicit)</strong>: Compounding the confusion, “mechanistic interpretability” is sometimes used to describe who wrote a paper rather than what methods or goals it involves.</li> </ol> <p>This definitional sprawl has diluted the original meaning of MI, particularly its grounding in causality.</p> <h2 id="mechanisms-causality-and-abstraction">Mechanisms, Causality, and Abstraction</h2> <p>Mechanistic interpretability derives its name from causal mechanisms. A causal mechanism can be understood as a lawful transformation: a function that maps some subset of model variables (causes) to another subset (effects).</p> <p>In neural networks, MI aims to discover the mechanisms that produce specific outputs from specific inputs, using intermediate representations as the primary level of abstraction.</p> <p>However, real-world causal systems—biological, physical, or artificial—are deeply complex. Multiple pathways can lead to the same outcome, making full causal explanations unwieldy. Human explanations are one way to manage this complexity: they distill explanations down to the most proximal or salient mechanisms.</p> <p>Neural networks offer a different option. Since we are not limited to human-scale explanations, MI often relies on causal abstraction—distilling complex causal structure into interpretable, tractable forms without restricting ourselves to only the most local mechanisms.</p> <h2 id="from-distill-to-reverse-engineering-neural-networks">From Distill to “Reverse Engineering Neural Networks”</h2> <p>The term mechanistic interpretability was coined by Chris Olah and first publicly used in posts on <a href="https://distill.pub/" rel="external nofollow noopener" target="_blank">Distill.pub</a>. Early work focused heavily on understanding how weights implement mechanisms, particularly in vision models.</p> <p>The phrase “reverse engineering neural networks” gained popularity later, especially after the Distill team moved to Anthropic and began publishing <a href="https://transformer-circuits.pub/" rel="external nofollow noopener" target="_blank">transformer circuit</a> threads. The term became so dominant that even the <a href="https://icml2024mi.pages.dev/" rel="external nofollow noopener" target="_blank">ICML 2024 MI Workshop</a> adopted it to define its scope.</p> <p>Ironically, much contemporary MI work no longer explicitly references causal mechanisms at all. Today, almost any form of internal inspection—causal or not—is often labeled “mechanistic interpretability.”</p> <h2 id="the-nlpimi-divide">The NLPI–MI Divide</h2> <p>A major theme in this discussion is the tension between two communities:</p> <ul> <li> <strong>NLPI (NLP Interpretability):</strong> Active since early LSTM and RNN models, publishing primarily in ACL and related venues.</li> <li> <strong>MI (Mechanistic Interpretability):</strong> Emerging largely from computer vision and alignment-oriented communities, later pivoting to NLP.</li> </ul> <p>One of the major points of tension was that, rather than building on NLPI’s extensive prior work or engaging with them, MI community started working on interpretability research independently, often reinventing earlier findings and repeating epistemological debates around:</p> <ul> <li>Correlation vs. causation</li> <li>Simple features vs. complex subnetworks</li> <li>Expressive mappings vs. constrained interpretations</li> </ul> <p>This duplication was not purely technical, it was cultural.</p> <p>Below discussed are some of the technical avenues where such duplication can be seen.</p> <h3 id="vector-semantics-old-lessons-new-names">Vector Semantics: Old Lessons, New Names</h3> <p>The explosion of vector semantics after word2vec sparked extensive work on interpreting embeddings. Many modern ideas like task vectors, steering vectors, additive representation properties, trace their lineage to this era.</p> <p>But early critics showed that embedding structure often reflects word frequency rather than deep semantic meaning. Many of these critiques remain highly relevant today as well, especially for correlational interpretability methods like similarity metrics and activation comparisons.</p> <h3 id="neurons-circuits-and-polysemanticity">Neurons, Circuits, and Polysemanticity</h3> <p>Both NLPI and MI have attempted to localize concepts within models:</p> <ul> <li>NLPI localized linguistic phenomena to neurons or layers.</li> <li>MI pursued neuron-level explanations and later circuits—subgraphs of neurons responsible for specific behaviors.</li> </ul> <p>Single-neuron analysis, however, has faced sustained criticism:</p> <ul> <li>Large models cannot be reduced to a sum of independent parts.</li> <li>Behavioral composition is often non-linear.</li> <li>Polysemanticity, where a neuron responds to multiple unrelated concepts, makes interpretation ambiguous.</li> </ul> <p>MI community tried to solve polysemanticity, one of the example was using sparse autoencoders (SAE), which still relies on the assumption of linearity and naturally emerging sparsity, but like earlier neuron analysis methods, it requires expensive causal validation.</p> <h3 id="probing-a-familiar-story">Probing: A Familiar Story</h3> <p>Probing methods originated in NLPI as a way to extract linguistic information from hidden states. They were criticized for weak baselines, and lot of times, probes were extracting more information from randomly initialized vectors than full trained networks</p> <p>Modern MI work often uses linear probes to project model states into interpretable subspaces, but these approaches inherit the same limitations:</p> <ul> <li>Weak causal grounding</li> <li>Sensitivity to probe capacity</li> <li>Ambiguity about what is truly encoded vs. what the probe learns</li> </ul> <h3 id="cultural-not-just-methodological-differences">Cultural, Not Just Methodological, Differences</h3> <p>During the early days, machine-learning in general was primarily attributed to computer vision research and lot of interpretability works were being done in CV only, shaping the methods NLP researchers adopted. The MI term itself was first used in CV contexts before migrating to NLP after breakthroughs like GPT-3.</p> <p>The deeper divide, however, was cultural:</p> <ul> <li>MI research initially lived on blogs, forums, Slack, and Discord.</li> <li>NLPI research lived in peer-reviewed venues like ACL.</li> </ul> <p>The absence of NLPI researchers from online forums was misread as disinterest, when it was largely a difference in publication norms.</p> <p>When MI researchers began publishing in conferences, they faced criticism for limited engagement with prior NLPI literature. Despite this, MI rapidly attracted resources, attention, and prestige, leading many NLPI researchers to adopt MI terminology.</p> <h2 id="everyone-is-mechanistic-now">“Everyone Is Mechanistic Now”</h2> <p>Today, most interpretability researchers identify, at least loosely, with MI. Funding and visibility have accelerated this shift, but terminology alone has not unified the field.</p> <p>Despite methodological overlap, differences in norms, goals, and epistemology remain.</p> <h2 id="why-this-still-matters">Why This Still Matters</h2> <p>For all the confusion and tension it introduced, the MI community has played a major role in revitalizing interpretability research. Its energy, resources, and ambition have expanded the field’s reach.</p> <p>At the same time, many MI researchers are motivated by AI alignment concerns, where the long-term value of MI is actively debated. It is possible that alignment priorities will eventually shift away from MI, taking some resources with them.</p> <p>But interpretability will persist.</p> <p>NLPI and MI researchers share too much in common, like scientific curiosity, social responsibility, and a commitment to understanding powerful models,for this work to disappear. As long as our models remain opaque, we will keep trying to open them up.</p> <p>And in that sense, the question is not whether mechanistic interpretability survives, but what we ultimately decide it means.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/lazy-ambitious/">Lazy Ambitious or Overthinking?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/pentagon-feature-geometry/">Feature Geometry in Toy Models - Pentagon vs Hexagon</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/non-uniform-sparsity/">Effects of Non-Uniform Sparsity on Superposition in Toy Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/are-you-doing-enough/">Myth of 'Are you Doing Enough?'</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Shreyans Jain. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"at a glance",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-repeat-reads",title:"repeat reads",description:"List of Blogs/articles i like to revisit from time to time",section:"Navigation",handler:()=>{window.location.href="/favblog/"}},{id:"post-paper-notes-mechanistic",title:"Paper Notes - Mechanistic?",description:"Paper Notes for the `Mechanistic?` Paper",section:"Posts",handler:()=>{window.location.href="/blog/2026/mechanistic/"}},{id:"post-lazy-ambitious-or-overthinking",title:"Lazy Ambitious or Overthinking?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/lazy-ambitious/"}},{id:"post-feature-geometry-in-toy-models-pentagon-vs-hexagon",title:"Feature Geometry in Toy Models - Pentagon vs Hexagon",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/pentagon-feature-geometry/"}},{id:"post-effects-of-non-uniform-sparsity-on-superposition-in-toy-models",title:"Effects of Non-Uniform Sparsity on Superposition in Toy Models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/non-uniform-sparsity/"}},{id:"post-myth-of-39-are-you-doing-enough-39",title:"Myth of 'Are you Doing Enough?'",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/are-you-doing-enough/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-visualizing-training",title:"Visualizing Training",description:"Visualize Training Dynamics of a Neural Network",section:"Projects",handler:()=>{window.location.href="/projects/viz_training/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6A%73%68%72%65%79%38@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/shreyansjainn","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shreyans-jain-4b063667","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/py_parrot","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>